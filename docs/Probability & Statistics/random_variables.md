---
layout: default
title: Discrete Distributions
nav_order: 6
parent: Probability & Statistics
---

## Temas

 - [Distribucion Binomial](#distribucion-binomial)

Los tipos de variables aleatorias discretas se clasifican com√∫nmente seg√∫n las distribuciones de probabilidad que describen c√≥mo se comportan los datos asociados a estas variables. 

## Distribucion Binomial

{: .note}
La distribuci√≥n binomial o distribuci√≥n bin√≥mica es una distribuci√≥n de probabilidad discreta que cuenta el n√∫mero de √©xitos en una secuencia de $$ùëõ$$ ensayos de Bernoulli independientes entre s√≠ con una probabilidad fija $$ùëù$$ de ocurrencia de √©xito entre los ensayos.

La distribuci√≥n binomial se utiliza con frecuencia para modelizar el n√∫mero de aciertos en una muestra de tama√±o $$ùëõ$$ extra√≠da con reemplazo de una poblaci√≥n de tama√±o N. 

Para cada experimento llamado **ensayo Bernoulli**, utilizamos una variable aleatoria que toma el valor 1 cuando se consigue un √©xito y el valor 0 en caso contrario. La variable aleatoria, suma de todas estas variables aleatorias, cuenta el n√∫mero de √©xitos y sigue una distribuci√≥n binomial. Es posible entonces obtener la probabilidad de k √©xitos en una repetici√≥n de n experimentos:

La ley binomial se utiliza en diversos campos de estudio, especialmente a trav√©s de pruebas estad√≠sticas que permiten interpretar datos y tomar decisiones en situaciones que dependen del azar. Debido a su sencilla definici√≥n, es una de las leyes de probabilidad que se estudian en los cursos introductorios de teor√≠a de la probabilidad.

### Ejemplo Explicativo

Supongamos que lanzamos una moneda tres veces $$N = 3$$, y cada lanzamiento tiene una probabilidad de 0.7 de ser cara. Los posibles resultados (espacio muestral) y la distribuci√≥n de $$X$$ ser√≠an:

- **0 caras (X = 0):** $$(Cruz, Cruz, Cruz)$$
  - Probabilidad: $$(1 - 0.7)^3 = 0.027 $$
- **1 cara (X = 1):** $$(Cara, Cruz, Cruz), (Cruz, Cara, Cruz), (Cruz, Cruz, Cara)$$
  - Probabilidad: $$ \binom{3}{1} \times 0.7^1 \times 0.3^2 = 0.189 $$
- **2 caras (X = 2):** $$(Cara, Cara, Cruz), (Cruz, Cara, Cara), (Cara, Cruz, Cara)$$
  - Probabilidad: $$ \binom{3}{2} \times 0.7^2 \times 0.3^1 = 0.441$$
- **3 caras (X = 3):** $$(Cara, Cara, Cara)$$
  - Probabilidad: $$ 0.7^3 = 0.343 $$

### Ejemplo de C√≥digo en Python

Para trabajar con la variable aleatoria binomial en Python, una de las herramientas m√°s √∫tiles y comunes es el m√≥dulo `numpy`, espec√≠ficamente la funci√≥n `numpy.random.binomial`. Este m√≥dulo facilita la simulaci√≥n de ensayos binomiales, permitiendo generar datos que siguen una distribuci√≥n binomial. 

Este c√≥digo utiliza la funci√≥n `np.random.binomial` para simular 1000 ensayos binomiales donde se lanzan 10 monedas por ensayo con una probabilidad de 0.7 de obtener cara en cada lanzamiento. Luego, genera un histograma para visualizar la distribuci√≥n de los resultados.

```python
import numpy as np
import matplotlib.pyplot as plt

def simulate_binomial(n, p, trials):
    """Simula 'trials' ensayos binomiales de 'n' lanzamientos con probabilidad 'p'."""
    results = np.random.binomial(n, p, trials)
    return results

# Par√°metros de la simulaci√≥n
n = 10  # N√∫mero de lanzamientos
p = 0.7  # Probabilidad de cara
trials = 1000  # N√∫mero de simulaciones

# Realizar simulaciones
results = simulate_binomial(n, p, trials)

# Visualizar resultados
plt.hist(results, bins=np.arange(n+2)-0.5, edgecolor='black', density=True)
plt.title('Distribuci√≥n Binomial de Caras en 10 Lanzamientos')
plt.xlabel('N√∫mero de Caras')
plt.ylabel('Frecuencia Relativa')
plt.xticks(range(n+1))
plt.show()
```

![Visualizaci√≥n de la Convergencia](https://fer78docs.github.io/assets/images/distribucion_binomial.png)


## Geometric Random Variable

### Ensayos Independientes de Bernoulli

{: .highlight}
Un ensayo independiente implica que el resultado de un ensayo no influye ni puede ser influenciado por los resultados de otros ensayos. En el contexto de lanzar una moneda, significa que el resultado de un lanzamiento no afecta el resultado del siguiente.

#### Ejemplo con Dos Lanzamientos
Si lanzamos una moneda dos veces con una probabilidad de 0.7 de sacar cara en cada lanzamiento, la probabilidad de obtener dos caras seguidas ser√≠a $$0.7 \times 0.7 = 0.49$$.

#### Explicaci√≥n y Ejemplo
Supongamos que lanzamos una moneda hasta que salga cara por primera vez, y queremos saber cu√°ntos lanzamientos se necesitan.

```python
def geometric_trial(p=0.7):
    """Simula una variable aleatoria geom√©trica.
    Args:
        p (float): Probabilidad de sacar cara. 
    Returns:
        int: N√∫mero de lanzamientos hasta el primer √©xito.
    """
    count = 1
    while bernoulli_trial(p) == 0:
        count += 1
    return count
```

Esta funci√≥n utiliza la funci√≥n de Bernoulli definida anteriormente para simular lanzamientos sucesivos hasta que el primer lanzamiento resulte en √©xito (cara).

### Funci√≥n de Masa de Probabilidad (PMF) de la Variable Geom√©trica

{: .highlight}
La PMF de una variable aleatoria geom√©trica da la probabilidad de que se necesite un n√∫mero espec√≠fico de ensayos para alcanzar el primer √©xito. 

#### Ejemplo

- $$P(X=1) = 0.7$$ (sacar cara en el primer lanzamiento).
- $$P(X=2) = 0.3 \times 0.7$$ (sacar cruz en el primero y cara en el segundo).
- $$P(X=n) = 0.3^{(n-1)} \times 0.7$$ (sacar cruz en los primeros $$n-1$$ lanzamientos y cara en el $$n$$-√©simo).

### Prueba de normalizaci√≥n de variable aleatoria geom√©trica opcional

Este segmento explica la variable aleatoria geom√©trica en detalle, destacando su importancia en el contexto de ensayos independientes de Bernoulli, como el lanzamiento repetido de una moneda hasta obtener el primer √©xito (cara). Adem√°s, se aborda la propiedad de normalizaci√≥n de la distribuci√≥n geom√©trica y se anticipa una demostraci√≥n pr√°ctica utilizando Python. Vamos a desglosar y ampliar estos conceptos y ejemplos en espa√±ol.

### Variable Aleatoria Geom√©trica

{: .highlight}
La variable aleatoria geom√©trica mide el n√∫mero de intentos necesarios hasta obtener el primer √©xito en una serie de ensayos independientes de Bernoulli. Por ejemplo, en el lanzamiento de una moneda, esta variable contar√≠a cu√°ntos lanzamientos se realizan hasta que aparece la primera cara, asumiendo que cada lanzamiento es independiente del anterior.

#### Propiedades de la Variable Geom√©trica

- **Espacio Muestral Infinito pero Contable:** La variable geom√©trica puede tomar una cantidad infinita de valores (1, 2, 3, ...), ya que te√≥ricamente podr√≠an requerirse infinitos lanzamientos para obtener una cara. Sin embargo, estos valores son contables, lo que clasifica a la variable como discreta.
- **Distribuci√≥n de Probabilidad:** La probabilidad de que la variable aleatoria geom√©trica tome un valor espec√≠fico $$k$$ es una funci√≥n de la probabilidad de √©xito $$p$$ y la probabilidad de fracaso $$q = 1-p$$. donde $$k$$ es el n√∫mero de lanzamientos realizados hasta obtener el primer √©xito.

$$P(X = k) = q^{k-1} \cdot p$$

### Aplicaci√≥n Pr√°ctica en Python

Este c√≥digo simula 1000 ensayos de una variable aleatoria geom√©trica y utiliza un histograma para visualizar cu√°ntos lanzamientos se necesitan t√≠picamente para obtener el primer √©xito. Esta visualizaci√≥n ayuda a comprender la naturaleza de la distribuci√≥n geom√©trica y la efectividad de los ensayos de Bernoulli independientes.

```python
import numpy as np
import matplotlib.pyplot as plt

def geometric_trial(p=0.7):
    count = 0
    while np.random.rand() >= p:
        count += 1
    return count + 1

# Simulaci√≥n de 1000 ensayos geom√©tricos
results = [geometric_trial(p=0.7) for _ in range(1000)]

# Visualizaci√≥n de la distribuci√≥n
plt.hist(results, bins=max(results), edgecolor='black')
plt.title('Distribuci√≥n de la Variable Aleatoria Geom√©trica')
plt.xlabel('N√∫mero de Lanzamientos hasta el Primer √âxito')
plt.ylabel('Frecuencia')
plt.show()
```
![Visualizaci√≥n de la Convergencia](https://fer78docs.github.io/assets/images/variable_aleatoria_geom√©trica.png)




## Cumulative Distribution Function 

La **Funci√≥n de Distribuci√≥n Acumulativa** (CDF, por sus siglas en ingl√©s "Cumulative Distribution Function") es una herramienta fundamental en teor√≠a de la probabilidad y estad√≠stica que describe la **acumulaci√≥n de probabilidad hasta un cierto valor de una variable aleatoria**. Vamos a explorar en detalle qu√© es, c√≥mo funciona, y sus aplicaciones principales.

{: .highlight}
Para una variable aleatoria $$X$$, la funci√≥n de distribuci√≥n acumulativa $$F_X(x)$$ se define como la probabilidad de que $$X$$ tome un valor menor o igual a $$x$$. Matem√°ticamente, esto se expresa como:
$$
F_X(x) = P(X \leq x)
$$
Esta funci√≥n proporciona una descripci√≥n completa de la distribuci√≥n de probabilidad de la variable aleatoria.

### Propiedades de la CDF

1. **No decreciente**: $$F_X(x)$$ es siempre una funci√≥n no decreciente de $$x$$. Esto significa que si $$a \leq b $$, entonces $$F_X(a) \leq F_X(b)$$.
2. **L√≠mites**: $$F_X(x)$$ tiene un l√≠mite de 0 cuando $$x$$ tiende a $$-\infty$$ y un l√≠mite de 1 cuando $$x$$ tiende a $$\infty$$).
3. **Continuidad por la derecha**: $$F_X(x)$$ es continua por la derecha en cada punto. Esto significa que $$\lim_{x \to x_0^+} F_X(x) = F_X(x_0)$$.
4. **Saltos en los valores de discontinuidad**: Los puntos donde $$F_X(x)$$ tiene saltos corresponden a los valores de $$x$$ donde la variable aleatoria $$X$$ puede tomar valores discretos con probabilidad positiva.

### Tipos de Variables Aleatorias y sus CDFs

- **Variables Discretas**: Para variables aleatorias discretas, la CDF es una funci√≥n escalonada que aumenta en puntos donde la variable aleatoria tiene masa de probabilidad.
- **Variables Continuas**: Para variables continuas, la CDF es una funci√≥n suave y continua. La derivada de la CDF, cuando existe, es la funci√≥n de densidad de probabilidad (PDF).
- **Variables Mixtas**: Algunas variables aleatorias tienen componentes tanto continuos como discretos, lo que resulta en una CDF que es en parte suave y en parte escalonada.

### Ejemplo Pr√°ctico

Supongamos que tienes una variable aleatoria $$X$$ que sigue una distribuci√≥n uniforme en el intervalo $$[0,1]$$. La CDF de $$X$$ es:
$$
F_X(x) = 
\begin{cases} 
0 & \text{si } x < 0 \\
x & \text{si } 0 \leq x \leq 1 \\
1 & \text{si } x > 1 
\end{cases}
$$
Este ejemplo muestra c√≥mo la CDF describe de manera efectiva la distribuci√≥n de $$X$$, indicando que cualquier valor dentro del intervalo [0,1] es igualmente probable.

En resumen, l**a funci√≥n de distribuci√≥n acumulativa es una herramienta esencial en probabilidad y estad√≠stica para entender c√≥mo se distribuyen los valores de una variable aleatoria a lo largo del espectro de posibles valores**.

La animaci√≥n del enlace muestra la relaci√≥n entre la `funci√≥n de masa de probabilidad` y la `funci√≥n de distribuci√≥n acumulativa`. El gr√°fico superior es el PMF, mientras que el gr√°fico inferior es el CDF correspondiente. Al observar la gr√°fica de una CDF, cada valor del eje y es la suma de las probabilidades menores o iguales que √©l en la PMF.

[Enlace a la animacion](https://static-assets.codecademy.com/skillpaths/master-stats-ii/probability-distributions/cdf-vs-pmf/animated.html)

Podemos usar una funci√≥n de distribuci√≥n acumulativa para calcular la probabilidad de un rango espec√≠fico tomando la diferencia entre dos valores de la funci√≥n de distribuci√≥n acumulativa. Por ejemplo, para encontrar la probabilidad de observar entre 3 y 6 caras, podemos tomar la probabilidad de observar 6 o menos cabezas y restar la probabilidad de observar 2 o menos caras. Esto deja un remanente de entre 3 y 6 cabezas.

La imagen de la derecha demuestra c√≥mo funciona esto. Es importante tener en cuenta que para incluir el l√≠mite inferior en el rango, el valor que se resta debe ser uno menos que el l√≠mite inferior. En este ejemplo, quer√≠amos saber la probabilidad de 3 a 6, que incluye 3. 

[Enlace a la animacion](https://static-assets.codecademy.com/skillpaths/master-stats-ii/probability-distributions/cdf-animation/animation.html)

### Usando la funci√≥n de distribuci√≥n acumulativa en Python

Podemos utilizar el m√©todo `binom.cdf()` de la biblioteca `scipy.stats` para calcular la funci√≥n de distribuci√≥n acumulativa. Este m√©todo toma 3 valores:

- `x`: el valor de inter√©s, buscando la probabilidad de este valor o menos
- `n`: el tama√±o de la muestra
- `p`: la probabilidad de √©xito

Calcular matem√°ticamente la probabilidad de observar 6 o menos caras en 10 lanzamientos de moneda justos (0 a 6 caras) se parece a lo siguiente:

```math
P(6 or fewer heads) = P(0 to 6 heads)
```
El codigo en Python es:
```python
import scipy.stats as stats

print(stats.binom.cdf(6, 10, 0.5))
```
Output
```
0.828125
```
Se puede pensar que calcular la probabilidad de observar entre 4 y 8 caras en 10 lanzamientos de moneda justos es tomar la diferencia del valor de la funci√≥n de distribuci√≥n acumulativa en 8 de la funci√≥n de distribuci√≥n acumulativa en 3:

```math
P(4 to 8 Heads) = P(0 to 8 Heads) ‚àí P(0 to 3 Heads)
```
En Python utilizamos el codigo:
```python
import scipy.stats as stats

print(stats.binom.cdf(8, 10, 0.5) - stats.binom.cdf(3, 10, 0.5))
```
Output
```
0.81738
```
Para calcular la probabilidad de observar m√°s de 6 caras en 10 lanzamientos de moneda justos, restamos el valor de la funci√≥n de distribuci√≥n acumulativa en 6 de 1. Matem√°ticamente, esto se parece a lo siguiente:
```math
P(more than 6 Heads) = 1 - P(6 or fewer Heads)
```
Tenga en cuenta que "m√°s de 6 cabezas" no incluye 6. En Python, calcular√≠amos esta probabilidad usando el siguiente c√≥digo:
```python
import scipy.stats as stats
print(1 - stats.binom.cdf(6, 10, 0.5))
```
Output
```
0.171875
```

## Random Variables in Real Datasets

Para explorar c√≥mo se utilizan las variables aleatorias en conjuntos de datos reales, se puede utilizar Python junto con bibliotecas como `Pandas` y `Seaborn` para cargar y analizar datos. Por ejemplo, el conjunto de datos de Iris es frecuentemente usado para este tipo de an√°lisis:

```python
import pandas as pd
import seaborn as sns

# Cargar el conjunto de datos de Iris
iris = sns.load_dataset('iris')

# Mostrar las primeras cinco filas del conjunto de datos
print(iris.head())

# Explorar las categor√≠as √∫nicas de la variable 'species'
print(iris['species'].unique())
```

Este c√≥digo carga el conjunto de datos de Iris, que incluye medidas como la longitud y el ancho del s√©palo y del p√©talo de diferentes especies de iris. Cada una de estas medidas se puede considerar como una variable aleatoria, donde los valores que toman son resultados de procesos aleatorios bajo condiciones controladas.

#### Tareas de Aprendizaje Autom√°tico
En el contexto del aprendizaje autom√°tico, las tareas com√∫nmente asociadas con variables aleatorias incluyen clasificaci√≥n y regresi√≥n:
- **Clasificaci√≥n:** Determinar a qu√© categor√≠a (especies en el caso de Iris) pertenece una observaci√≥n basada en sus caracter√≠sticas.
- **Regresi√≥n:** Predecir un valor continuo basado en otras variables (por ejemplo, predecir el largo del p√©talo basado en otras medidas).

Estas tareas utilizan las propiedades de las variables aleatorias para entrenar modelos que puedan generalizar bien a partir de datos nuevos.

### Modelado de Variables Aleatorias en Python

Para modelar variables aleatorias y sus distribuciones en Python, se utilizan t√©cnicas estad√≠sticas y de aprendizaje autom√°tico para ajustar modelos a los datos. Esto puede implicar calcular la funci√≥n de masa de probabilidad para variables discretas o la funci√≥n de densidad de probabilidad para variables continuas.

#### Visualizaci√≥n y An√°lisis
Utilizar visualizaciones como histogramas o gr√°ficos de dispersi√≥n ayuda a entender la distribuci√≥n y la relaci√≥n entre variables aleatorias. Por ejemplo:

```python
sns.pairplot(iris, hue='species')
plt.show()
```

Este gr√°fico muestra las relaciones entre todas las medidas en el conjunto de datos de Iris, coloreadas por especie, proporcionando una intuici√≥n visual de c√≥mo las variables aleatorias se relacionan entre s√≠ y c√≥mo podr√≠an influir en la clasificaci√≥n de las especies.

Comprender c√≥mo las variables aleatorias se aplican a datos reales permite a los cient√≠ficos de datos y a los profesionales del aprendizaje autom√°tico construir modelos m√°s precisos y efectivos. La teor√≠a detr√°s de las variables aleatorias es fundamental, pero su aplicaci√≥n pr√°ctica a trav√©s de herramientas como Python facilita la exploraci√≥n y el modelado efectivo de datos complejos en situaciones del mundo real.

