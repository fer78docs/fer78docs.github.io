---
layout: default
title: Expectation
nav_order: 6
parent: Probability & Statistics
---

## Expectativa

El concepto de **expectativa** (o valor esperado) es fundamental en el campo de la probabilidad y estad칤sticas. **La expectativa proporciona un resumen num칠rico central de una variable aleatoria, ofreciendo una medida de la "tendencia central" o el promedio a largo plazo que uno puede esperar en una serie de experimentos** donde la variable aleatoria se observa repetidamente.

{: .highlight}
La expectativa de una variable aleatoria $$X$$, denotada como $$E[X]$$ o $$\mu$$, es el promedio ponderado de todos los posibles valores que $$X$$ puede tomar, ponderados por la probabilidad de cada valor. Matem치ticamente se define de diferentes maneras dependiendo de si la variable aleatoria es discreta o continua:

- **Variable Discreta**: Si $$X$$ es una variable aleatoria discreta que toma valores $$(x_1, x_2, x_3, \dots)$$ con probabilidades $$(p_1, p_2, p_3, \dots)$$, entonces el valor esperado de $$X$$ se calcula como:

  $$
  E[X] = \sum_{i} x_i p_i
  $$

  donde la suma se extiende sobre todos los valores posibles de $$X$$.

Ejemplo: Calcularemos la expectativa de una variable aleatoria que sigue una distribuci칩n binomial, donde 
$$洧녵 = 10$$ (n칰mero de ensayos) y $$洧녷 = 0.5$$ (probabilidad de 칠xito en cada ensayo).

```python
import scipy.stats as stats

# Par치metros de la distribuci칩n binomial
n = 10  # n칰mero de ensayos
p = 0.5  # probabilidad de 칠xito

# Crear una variable aleatoria binomial
binomial_var = stats.binom(n, p)

# Calcular la expectativa
expected_value = binomial_var.mean()
print("Expectativa de la variable binomial:", expected_value)
```

- **Variable Continua**: Si $$X$$ es una variable aleatoria continua con una funci칩n de densidad de probabilidad (PDF) $$f(x)$$, el valor esperado se define como:

  $$
  E[X] = \int_{-\infty}^{\infty} x f(x) \, dx
  $$

  donde la integral se eval칰a sobre todo el rango de $$X$$.

Ejemplo: Calcular la expectativa de una variable aleatoria que sigue una distribuci칩n normal, con media $$洧랞 = 0$$ y desviaci칩n est치ndar $$洧랥 = 1$$.

```python
# Par치metros de la distribuci칩n normal
mu = 0  # media
sigma = 1  # desviaci칩n est치ndar

# Crear una variable aleatoria normal
normal_var = stats.norm(mu, sigma)

# Calcular la expectativa
expected_value = normal_var.mean()
print("Expectativa de la variable normal:", expected_value)
```

### Generalizando el C치lculo de la Expectativa

Para otras distribuciones, puedes seguir un procedimiento similar utilizando las funciones proporcionadas por SciPy para esa distribuci칩n espec칤fica. Aqu칤 est치 c칩mo se har칤a de forma general:

```python
# Para una distribuci칩n general, reemplazar 'dist' con el nombre de la distribuci칩n
# y configurar sus par치metros espec칤ficos.
dist_var = stats.dist(param1, param2, ...)

# Calcular la expectativa
expected_value = dist_var.mean()
print("Expectativa de la distribuci칩n:", expected_value)
```

## Ley de los Grandes Numeros

{: .note}
La Ley de los Grandes N칰meros (LLN) es un teorema fundamental en teor칤a de la probabilidad que describe el resultado de realizar el mismo experimento un gran n칰mero de veces. Seg칰n la LLN, **el promedio de los resultados obtenidos de un gran n칰mero de pruebas se acercar치 al valor esperado a medida que se incremente el n칰mero de pruebas**. Esto implica que las frecuencias relativas de los resultados convergen a las probabilidades te칩ricas.

### LLN D칠bil vs. LLN Fuerte

- **LLN D칠bil**: Asegura que, para cualquier tolerancia $$\epsilon > 0$$, la probabilidad de que el promedio de las muestras difiera del valor esperado por m치s de $$\epsilon$$ tiende a cero conforme el tama침o de la muestra se hace infinitamente grande.

- **LLN Fuerte**: Establece que con probabilidad 1, el promedio de las muestras converge al valor esperado cuando el tama침o de la muestra tiende a infinito.

### Simulaciones Estad칤sticas en Python

#### Generaci칩n de Datos

Usaremos Python para simular datos utilizando m칩dulos como `numpy` y `scipy`. Por ejemplo, para simular una variable aleatoria binomial, podemos usar el siguiente c칩digo:

```python
import numpy as np
# Simular 1000 ensayos de una distribuci칩n binomial con n=10 y p=0.5
data = np.random.binomial(10, 0.5, 1000)
```

#### C치lculo de Promedios

Para calcular el promedio de los datos simulados y compararlos con el valor esperado:

```python
average = np.mean(data)
print("Promedio calculado:", average)
```

#### An치lisis de Datos y Estimaci칩n de Par치metros

- Interpretaci칩n de Resultados: Los resultados de las simulaciones deben interpretarse en el contexto de la LLN. Por ejemplo, si el promedio calculado de los ensayos binomiales difiere significativamente del valor esperado (5 en este caso), se deber칤a aumentar el n칰mero de ensayos.

- Estimaci칩n de Par치metros: La estimaci칩n de par치metros puede mejorar utilizando m칠todos como el de M치xima Verosimilitud o los M칠todos de Momentos. Esto permite ajustar los par치metros de la distribuci칩n a partir de los datos observados para que coincidan m치s estrechamente con el valor te칩rico esperado.

```python
import matplotlib.pyplot as plt
import numpy as np

# Simular progresivamente mayores cantidades de ensayos
sample_sizes = np.arange(100, 10000, 10)
averages = [np.mean(np.random.binomial(10, 0.5, size)) for size in sample_sizes]

# Graficar los resultados
plt.plot(sample_sizes, averages, label="Promedio de Ensayos Binomiales")
plt.axhline(y=5, color='r', linestyle='--', label="Valor Esperado")
plt.xlabel("Tama침o de la Muestra")
plt.ylabel("Promedio Calculado")
plt.legend()
plt.show()
```

![Grandes Numeros](https://fer78docs.github.io/assets/images/grandes_numeros.png)


##  Independencia y Distribuci칩n Id칠ntica de las Muestras (IID)

{: .note}
Datos independientes e id칠nticamente distribuidos (IID) **son aquellos donde cada dato en una muestra es generado de manera independiente de los otros y todos siguen exactamente la misma distribuci칩n de probabilidad.** Esta propiedad es esencial para aplicar correctamente la Ley de los Grandes N칰meros.

En contextos experimentales, garantizar que los datos son IID implica dise침ar experimentos donde las intervenciones externas o las condiciones previas no afectan los resultados de cada prueba. Por ejemplo, en ensayos cl칤nicos, los sujetos deben ser asignados aleatoriamente a grupos de tratamiento para asegurar la independencia.

### Relaci칩n entre Muestras y la Poblaci칩n

- **Media de la Poblaci칩n vs. Media de la Muestra**: La media de la poblaci칩n es el valor promedio de un par치metro en toda la poblaci칩n, mientras que la media de la muestra se calcula de la misma manera pero solo utilizando una parte de la poblaci칩n. La Ley de los Grandes N칰meros asegura que estas dos medias converjan a medida que el tama침o de la muestra aumenta.

- **Estimaci칩n de Par치metros**: La estimaci칩n de par치metros se realiza utilizando la media de la muestra y otras estad칤sticas para hacer inferencias sobre la poblaci칩n total. Esto es fundamental en 치reas como la demograf칤a y la investigaci칩n de mercado, donde no es pr치ctico estudiar a toda la poblaci칩n.

### 4. Ejemplos de Variables Aleatorias y sus Expectativas

**Variables Discretas Comunes**:
   - **Bernoulli**: Eventos de 칠xito/fallo; la expectativa es \(p\).
   - **Binomial**: N칰mero de 칠xitos en \(n\) ensayos de Bernoulli; expectativa \(np\).
   - **Geom칠trica**: N칰mero de ensayos hasta el primer 칠xito; expectativa \(1/p\).
   - **Poisson**: N칰mero de eventos en un intervalo fijo; expectativa \(\lambda\).

**Variables Continuas Comunes**:
   - **Normal (Gaussiana)**: Distribuida sim칠tricamente alrededor de la media; la expectativa es \(\mu\).
   - **Exponencial**: Tiempo entre eventos en un proceso de Poisson; expectativa \(1/\lambda\).

### 5. Simulaciones en Python

**Generaci칩n de Datos Aleatorios**:
Utilizaci칩n de `numpy` y `scipy` para generar datos simulados y aplicar la LLN. Se explicar치 c칩mo generar datos para cada tipo de distribuci칩n mencionada anteriormente.

**Verificaci칩n de la Ley de los Grandes N칰meros**:
Demostraciones pr치cticas y gr치ficas utilizando `matplotlib` para mostrar c칩mo la media de la muestra converge hacia la media poblacional con el aumento del tama침o de la muestra.

### 6. Implicaciones Pr치cticas de la Ley de los Grandes N칰meros

**Estimaci칩n de Par치metros en la Vida Real**:
Discusi칩n sobre c칩mo los economistas y otros profesionales utilizan grandes bases de datos para estimar par치metros econ칩micos, demogr치ficos o de salud p칰blica y c칩mo esto afecta la formulaci칩n de pol칤ticas y decisiones empresariales.

**Desaf칤os y Consideraciones**:
An치lisis de las limitaciones de la LLN, especialmente en datos correlacionados o en distribuciones con colas pesadas donde las varianzas son altas o infinitas.

### 7. Conclusi칩n

**Resumen del Tema**:
Se reitera

 la importancia de la Ley de los Grandes N칰meros en estad칤stica y se resumen los puntos clave discutidos.

**Pr칩ximos Pasos y Recursos Adicionales**:
Se ofrecen direcciones para estudios futuros, incluyendo enlaces a recursos avanzados para aquellos interesados en explorar m치s all치 de los fundamentos estad칤sticos.